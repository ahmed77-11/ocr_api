{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fraud_pipeline_tf.py\n",
    "\"\"\"\n",
    "End-to-End Fraud Detection Pipeline for Bank Drafts using TensorFlow\n",
    "\n",
    "Steps:\n",
    "1. Synthetic Data Generation (prototyping)\n",
    "2. Persist Historical Drafts into a Database (SQLite/Postgres)\n",
    "3. Build & Refresh Statistics (RIB-level, Bank-level, Population-level)\n",
    "4. Train TensorFlow Models:\n",
    "     - Autoencoder for anomaly detection on amounts\n",
    "     - MLP classifier for supervised fraud detection\n",
    "5. Serialize Models & Stats\n",
    "6. Inference Function to score new OCR-extracted drafts\n",
    "7. Onboard new RIB statistics after approval\n",
    "\n",
    "Usage:\n",
    "  python fraud_pipeline_tf.py generate\n",
    "  python fraud_pipeline_tf.py train --data <data_csv> --model-dir <model_dir>\n",
    "  python fraud_pipeline_tf.py predict --ocr <ocr_json> --model-dir <model_dir>\n",
    "  python fraud_pipeline_tf.py onboard --rib <rib> --amt <amount>\n",
    "\n",
    "Dependencies:\n",
    "  pandas, numpy, faker, num2words, sqlalchemy, joblib, tensorflow\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from num2words import num2words\n",
    "from sqlalchemy import create_engine\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# ---------- 0. Configuration ----------\n",
    "DB_URI = 'sqlite:///drafts.db'  # or your PostgreSQL URI\n",
    "ENGINE = create_engine(DB_URI)\n",
    "\n",
    "# ---------- Utility Functions ----------\n",
    "def is_valid_rib(v: str) -> bool:\n",
    "    s = v.replace(' ', '').replace('-', '')\n",
    "    if len(s) != 20:\n",
    "        return False\n",
    "    n = int(s[:-2] + '00')\n",
    "    chk = 97 - (n % 97)\n",
    "    return chk == int(s[-2:])\n",
    "\n",
    "\n",
    "def amount_to_words_fr(x: float) -> str:\n",
    "    text = num2words(x, lang='fr')\n",
    "    return text.replace('virgule', 'dinars zéro')\n",
    "\n",
    "# ---------- 1. Synthetic Data Generation ----------\n",
    "F = Faker('fr_FR'); Faker.seed(42); random.seed(42)\n",
    "\n",
    "def generate_valid_rib():\n",
    "    def valid(v: str) -> bool:\n",
    "        s = v.replace(' ', '').replace('-', '')\n",
    "        if len(s) != 20: return False\n",
    "        n = int(s[:-2] + '00')\n",
    "        return 97 - (n % 97) == int(s[-2:])\n",
    "    while True:\n",
    "        base = ''.join(str(random.randint(0,9)) for _ in range(18))\n",
    "        for i in range(100):\n",
    "            cand = base + f\"{i:02d}\"\n",
    "            if valid(cand): return cand\n",
    "\n",
    "def generate_synthetic(n_legit=3500, n_fraud=500):\n",
    "    \"\"\"\n",
    "    Generate synthetic drafts with varied fraud patterns:\n",
    "    - amount_words always matches amount_digits (for both legit & fraud)\n",
    "    - fraud rows randomly exhibit one of several fraud types:\n",
    "      * Missing signature\n",
    "      * Invalid barcode\n",
    "      * Invalid RIB format\n",
    "      * Amount incompatible (extreme outlier)\n",
    "      * Mismatch words vs digits (optional)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    fraud_patterns = [\n",
    "        'missing_signature',\n",
    "        'invalid_barcode',\n",
    "        'invalid_rib',\n",
    "        'amount_outlier',\n",
    "        'words_mismatch'\n",
    "    ]\n",
    "    for fraud in [False] * n_legit + [True] * n_fraud:\n",
    "        amt = round(random.uniform(500, 10000), 3)\n",
    "        # always correct literal words\n",
    "        words = amount_to_words_fr(amt)\n",
    "        rib = generate_valid_rib()\n",
    "        sig = True\n",
    "        barcode_valid = True\n",
    "        # apply fraud patterns\n",
    "        if fraud:\n",
    "            pattern = random.choice(fraud_patterns)\n",
    "            if pattern == 'missing_signature':\n",
    "                sig = False\n",
    "            elif pattern == 'invalid_barcode':\n",
    "                barcode_valid = False\n",
    "            elif pattern == 'invalid_rib':\n",
    "                # corrupt last two digits\n",
    "                rib = rib[:-2] + f\"{random.randint(0,99):02d}\"\n",
    "            elif pattern == 'amount_outlier':\n",
    "                # assign extreme amount\n",
    "                amt = round(random.uniform(20000, 50000), 3)\n",
    "                words = amount_to_words_fr(amt)\n",
    "            elif pattern == 'words_mismatch':\n",
    "                # intentionally corrupt words\n",
    "                words = words + \" erreurs\"\n",
    "        rows.append({\n",
    "            'traite_num': str(F.random_number(digits=12)),\n",
    "            'amount_digits': amt,\n",
    "            'amount_words': words,\n",
    "            'bank': F.company(),\n",
    "            'rib': rib,\n",
    "            'signature_detected': sig,\n",
    "            'barcode_validates_traite': barcode_valid,\n",
    "            'fraud_label': int(fraud)\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_sql('drafts', ENGINE, if_exists='replace', index=False)\n",
    "    print(\"Synthetic data generated with varied fraud patterns.\")\n",
    "    return df\n",
    "\n",
    "# ---------- 2 & 3. Build/Refresh Stats ----------\n",
    "def build_stats():\n",
    "    df = pd.read_sql('drafts', ENGINE)\n",
    "    pop = df['amount_digits']\n",
    "    pop_stats = {'mean':pop.mean(),'std':pop.std(),'lo':pop.quantile(0.01),'hi':pop.quantile(0.99)}\n",
    "    rib_stats = df.groupby('rib')['amount_digits'].agg(\n",
    "        mean_amount='mean', std_amount='std', count='count',\n",
    "        pct_1=lambda x: x.quantile(0.01), pct_99=lambda x: x.quantile(0.99)\n",
    "    )\n",
    "    bank_stats = df.groupby('bank')['amount_digits'].agg(\n",
    "        mean='mean', std='std', lo=lambda x: x.quantile(0.01), hi=lambda x: x.quantile(0.99)\n",
    "    )\n",
    "    return pop_stats, rib_stats, bank_stats\n",
    "\n",
    "# ---------- 4. Model Training ----------\n",
    "def train(data_csv: str, model_dir: str):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    df = pd.read_csv(data_csv)\n",
    "    pop_stats, rib_stats, bank_stats = build_stats()\n",
    "    # Autoencoder for amount anomaly\n",
    "    amounts = df[['amount_digits']].values.astype('float32')\n",
    "    inp = layers.Input(shape=(1,))\n",
    "    x = layers.Dense(8, activation='relu')(inp)\n",
    "    x = layers.Dense(4, activation='relu')(x)\n",
    "    x = layers.Dense(8, activation='relu')(x)\n",
    "    out = layers.Dense(1)(x)\n",
    "    autoenc = models.Model(inp, out)\n",
    "    autoenc.compile(optimizer='adam', loss='mse')\n",
    "    autoenc.fit(amounts, amounts,\n",
    "                epochs=20, batch_size=32,\n",
    "                validation_split=0.2,\n",
    "                callbacks=[callbacks.EarlyStopping(patience=5)])\n",
    "    autoenc.save(f\"{model_dir}/autoencoder\")\n",
    "    # Prepare features for MLP classifier\n",
    "    # For simplicity, only using numeric signals here\n",
    "    df['mismatch'] = df.apply(lambda r: r['amount_words'].strip()!=amount_to_words_fr(r['amount_digits']).strip(), axis=1)\n",
    "    df['sig_missing'] = ~df['signature_detected']\n",
    "    df['barcode_bad'] = ~df['barcode_validates_traite']\n",
    "    df['rib_invalid'] = ~df['rib'].apply(is_valid_rib)\n",
    "    # z-score fallback\n",
    "    def compute_z(r):\n",
    "        rib, amt, bank = r['rib'], r['amount_digits'], r['bank']\n",
    "        if rib in rib_stats.index and rib_stats.at[rib,'count']>=5:\n",
    "            s=rib_stats.loc[rib]; μ,σ=s['mean_amount'],s['std_amount']\n",
    "        elif bank in bank_stats.index:\n",
    "            s=bank_stats.loc[bank]; μ,σ=s['mean'],s['std']\n",
    "        else:\n",
    "            μ,σ=pop_stats['mean'],pop_stats['std']\n",
    "        return (amt-μ)/σ if σ>0 else 0\n",
    "    df['z_score'] = df.apply(compute_z, axis=1)\n",
    "    df['amount_incompatible'] = df['z_score'].abs()>3\n",
    "    X = df[['amount_digits','mismatch','sig_missing','barcode_bad','rib_invalid','z_score','amount_incompatible']].astype('float32')\n",
    "    y = df['fraud_label'].values\n",
    "    # MLP classifier\n",
    "    clf_in = layers.Input(shape=(X.shape[1],))\n",
    "    y1 = layers.Dense(16, activation='relu')(clf_in)\n",
    "    y1 = layers.Dense(8, activation='relu')(y1)\n",
    "    y1 = layers.Dense(1, activation='sigmoid')(y1)\n",
    "    clf = models.Model(clf_in, y1)\n",
    "    clf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    clf.fit(X, y, epochs=30, batch_size=32, validation_split=0.2,\n",
    "            callbacks=[callbacks.EarlyStopping(patience=5)])\n",
    "    clf.save(f\"{model_dir}/classifier\")\n",
    "    # save stats\n",
    "    joblib.dump({'pop':pop_stats,'rib':rib_stats,'bank':bank_stats}, f\"{model_dir}/stats.pkl\")\n",
    "    print(f\"Models saved in {model_dir}\")\n",
    "\n",
    "# ---------- 5. Inference ----------\n",
    "def predict(ocr_json: dict, model_dir: str) -> dict:\n",
    "    # load models & stats\n",
    "    autoenc = tf.keras.models.load_model(f\"{model_dir}/autoencoder\")\n",
    "    clf = tf.keras.models.load_model(f\"{model_dir}/classifier\")\n",
    "    stats = joblib.load(f\"{model_dir}/stats.pkl\")\n",
    "    pop, rib_stats, bank_stats = stats['pop'], stats['rib'], stats['bank']\n",
    "    # prepare features\n",
    "    amt = float(ocr_json['amount_digits'])\n",
    "    mismatch = float(ocr_json['amount_words'].strip()!=amount_to_words_fr(amt).strip())\n",
    "    sig_missing = float(not ocr_json['signature_detects'])\n",
    "    barcode_bad = float(not ocr_json['barcode_validates_traite'])\n",
    "    rib_invalid = float(not is_valid_rib(ocr_json['rib']))\n",
    "    # z-score\n",
    "    bank = ocr_json['bank']\n",
    "    if ocr_json['rib'] in rib_stats.index and rib_stats.at[ocr_json['rib'],'count']>=5:\n",
    "        s=rib_stats.loc[ocr_json['rib']]; μ,σ=s['mean_amount'],s['std_amount']\n",
    "    elif bank in bank_stats.index:\n",
    "        s=bank_stats.loc[bank]; μ,σ=s['mean'],s['std']\n",
    "    else:\n",
    "        μ,σ=pop['mean'],pop['std']\n",
    "    z = (amt-μ)/σ if σ>0 else 0\n",
    "    amount_incompatible = float(abs(z)>3)\n",
    "    # anomaly score from autoencoder\n",
    "    recon = autoenc.predict(np.array([[amt]]))\n",
    "    err = float(np.abs(recon-amt))\n",
    "    # classifier predict\n",
    "    features = np.array([[amt, mismatch, sig_missing, barcode_bad, rib_invalid, z, amount_incompatible]], dtype='float32')\n",
    "    fraud_prob = float(clf.predict(features)[0,0])\n",
    "    # combine signals or return prob\n",
    "    return {'fraud_score': fraud_prob, 'anomaly_error': err, 'fraud_label': fraud_prob>0.5}\n",
    "\n",
    "# ---------- 6. Onboard New RIB ----------\n",
    "def onboard(rib: str, amt: float):\n",
    "    # after inserting a new draft record, refresh stats\n",
    "    build_stats()\n",
    "    print(f\"Onboarded {rib}\")\n",
    "\n",
    "# ---------- 7. CLI Entrypoint ----------\n",
    "if __name__=='__main__':\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument('command', choices=['generate','train','predict','onboard'])\n",
    "    p.add_argument('--data', help='CSV path')\n",
    "    p.add_argument('--model-dir', help='Directory for saving/loading TF models')\n",
    "    p.add_argument('--ocr', help='OCR JSON path')\n",
    "    p.add_argument('--rib', help='RIB to onboard')\n",
    "    p.add_argument('--amt', type=float, help='Amount for onboard')\n",
    "    args=p.parse_args()\n",
    "    if args.command=='generate': generate_synthetic()\n",
    "    elif args.command=='train': train(args.data, args.model_dir)\n",
    "    elif args.command=='predict':\n",
    "        j=json.load(open(args.ocr)); print(predict(j,args.model_dir))\n",
    "    elif args.command=='onboard': onboard(args.rib,args.amt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
